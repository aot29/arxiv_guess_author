{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b48a1d3-265f-4fde-9530-697bcda2dd50",
   "metadata": {},
   "source": [
    "# Test: Using a topic model to guess authors of a paper submitted for blind peer review\n",
    "\n",
    "Goal: **Guess the authors of a paper submitted for blind peer review.**\n",
    "\n",
    "A guess should be made based solely on: text (abstract), citations, year of submission and target journal. No other information is available at the time of submission, notably the article classification used by the journal is not always available at the time of submission.\n",
    "\n",
    "Assumption: **An individual author writes about similar topics within a short time range.**\n",
    "\n",
    "This is essential while choosing the dataset to conduct the experiment. Data was obtained by querying arXiv for articles in physics (the largest category on arXiv), published in the last 2 years. This limit is arbitrary and results from the assumption that most researchers will not publish about an unrelated topic within such a short period of time.\n",
    "\n",
    "Therefore: **It should be possible to compute a \"topic profile\" for individual authors by extracting the topics of all their articles.**\n",
    "\n",
    "Based on these topic profiles, it should be possible to compute the \"topic distance\" between two authors. Guessing the author of an article then becomes extracting the topics from the article and finding the authors with the most similar topic profile, i.e. with the shortest topic distance to the article.\n",
    "\n",
    "### Workflow\n",
    "\n",
    "#### Data acquisition ([01_process_snapshot](./01_process_snapshot.ipynb))\n",
    "A data dump was obtained from ArXiv [1]. The data contains metadata and abstracts for 2.412.624 articles. The data was augmented with columns for:\n",
    "* year of submission to arXiv\n",
    "* binary columns for broad categories (\"Computer Science\", \"Economics\", \"Mathematics\", \"Physics\", etc.), an article can be classified within multiple categories.\n",
    "\n",
    "#### Data preparation ([02_prepare_data](./02_prepare_data.ipynb))\n",
    "The data was queried for all articles on Physics (the largest category on arXiv), submitted since beginning 2023 (assuming that researchers are active in the present). The data has 90.530 articles, written by 246.443 authors. The data was split in train (50%), validate (25%) and test (25%) datasets. \n",
    "\n",
    "In order to prepare the article abstracts for topic analysis, the abstract were processed as follows:\n",
    "* Apply pre-processing filters: strip_tags, strip_punctuation, strip_multiple_whitespaces, stric_numeric, remove_stopwords, strip_short. For the exact function of each filter see [2].\n",
    "* Apply lemmatization. Lemmatization was accomplished using the NLTK Library.\n",
    "\n",
    "\n",
    "\n",
    "### References\n",
    "* [1] arXiv.org submitters. (2024). arXiv Dataset [Data set]. Kaggle. https://doi.org/10.34740/KAGGLE/DSV/7548853\n",
    "* [2] [The gensim preprocessing module](https://github.com/piskvorky/gensim/blob/develop/gensim/parsing/preprocessing.py)\n",
    "* [3] [WordNetLemmatizer in NLTK library documentation](https://www.nltk.org/api/nltk.stem.WordNetLemmatizer.html?highlight=wordnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f7237a-1890-4b8f-8d5b-848a68e96a72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
