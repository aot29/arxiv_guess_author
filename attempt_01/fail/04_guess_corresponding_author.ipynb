{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44437728-9535-458e-94e5-99f40641bc73",
   "metadata": {},
   "source": [
    "# Guess corresponding author\n",
    "* Load the article metadata and the topics assigned to each article\n",
    "* Define a baseline\n",
    "* Train a classifier\n",
    "* Evaluate the results on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7bc68ae-9340-437e-925f-1f218d5392cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d898fa2c-4db5-4608-a2a0-e61d031b6caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data'\n",
    "MODELS_PATH = '../models'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d44c0c-0dbd-4874-8b38-a11a8ba0c593",
   "metadata": {},
   "source": [
    "## Load the article metadata and the topics assigned to each article"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1146420d-0890-430a-9700-e08cd49ac108",
   "metadata": {},
   "source": [
    "Load the article abstracts and metadata for the train/validate/test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "070069ea-9d43-45a1-b672-bd91e1da61ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(os.path.join(DATA_PATH, 'arxiv_train.csv'), index_col=0)\n",
    "validate_df = pd.read_csv(os.path.join(DATA_PATH, 'arxiv_validate.csv'), index_col=0)\n",
    "test_df = pd.read_csv(os.path.join(DATA_PATH, 'arxiv_test.csv'), index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4a3f73-42d1-4b3f-9ab7-dc007a44988f",
   "metadata": {},
   "source": [
    "Load the topics assigned to each article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51b3b4ce-c99a-44a0-9f82-b766fc0120b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_train_df = pd.read_csv(os.path.join(DATA_PATH, 'topics_train.csv'), index_col=0)\n",
    "topics_validate_df = pd.read_csv(os.path.join(DATA_PATH, 'topics_validate.csv'), index_col=0)\n",
    "topics_test_df = pd.read_csv(os.path.join(DATA_PATH, 'topics_test.csv'), index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ed8751-d624-4a15-b917-807bf4f6ee4f",
   "metadata": {},
   "source": [
    "The \"labels\" in this case are the corresponding authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b04d67c-9270-4b91-a1b3-316f627c3f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = train_df[\"submitter\"]\n",
    "labels_validate = validate_df[\"submitter\"]\n",
    "labels_test = test_df[\"submitter\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5e40a49-a944-4fe5-b4f3-8b6fa1ac234e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train dataset has 35000 articles by 27356 unique correspponding authors\n",
      "The validate dataset has 17500 articles by 15197 unique correspponding authors\n",
      "The test dataset has 17500 articles by 15165 unique correspponding authors\n"
     ]
    }
   ],
   "source": [
    "print(f\"The train dataset has {train_df.shape[0]} articles by {len(set(labels_train))} unique correspponding authors\")\n",
    "print(f\"The validate dataset has {validate_df.shape[0]} articles by {len(set(labels_validate))} unique correspponding authors\")\n",
    "print(f\"The test dataset has {test_df.shape[0]} articles by {len(set(labels_test))} unique correspponding authors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b920109f-bb8f-4022-9d3c-4d67602fdf5c",
   "metadata": {},
   "source": [
    "## Baseline 10 most prolific submitters\n",
    "Take the 10 most prolific authors in the train dataset.\n",
    "A paper in the validation dataset may be classified into having been written by one of these top-10 authors, or \"other\" (so there are 11 classes).\n",
    "Compute the \"most frequent\" baseline based on validation dataset,based on the most probable class (which is of couse \"other\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7cfe5b85-083e-4c8f-b7c6-5b40b96fce4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the 10 authors from the \"submitter\" column that have written the most, based on the train dataset\n",
    "top100 = list(train_df.submitter.value_counts()[:10000].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "456438bf-fc50-4d17-96b6-6c6080ea9464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 100 authors in the train datasets wrote 3493 out of 17500 papers in the validate dataset, so 80% is the baseline for a classifier that can distinguish between one of the top 100 authors and 'other'.\n"
     ]
    }
   ],
   "source": [
    "# count papers in the validation dataset written by these authors\n",
    "papers_top100_count = 0\n",
    "for paper_authors in validate_df['submitter']:\n",
    "    for author in top100:\n",
    "        if author in paper_authors: \n",
    "            papers_top100_count += 1\n",
    "            break\n",
    "papers_top100_perc = papers_top100_count / validate_df.shape[0] * 100\n",
    "print(f\"The top 100 authors in the train datasets wrote {papers_top100_count} out of {validate_df.shape[0]} papers in the validate dataset, \\\n",
    "so {100 - papers_top100_perc:.0f}% is the baseline for a classifier that can distinguish between one of the top 100 authors and 'other'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8eb2190-39ca-42e0-9d85-c7c4716aec39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the 'most frequent' baseline for the validation dataset is 0.00.\n"
     ]
    }
   ],
   "source": [
    "dummy = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy.fit(validate_df, labels_validate)\n",
    "baseline_score_validate = dummy.score(validate_df, labels_validate)\n",
    "print(\"The accuracy of the 'most frequent' baseline for the validation dataset is {:.2f}.\".format(baseline_score_validate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39174a24-2cc7-4b57-b386-a3830eca57ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
