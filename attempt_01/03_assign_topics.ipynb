{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3101b10e-2125-4937-9535-dc2a044fc546",
   "metadata": {},
   "source": [
    "# Assign topics to each article\n",
    "* Load the train/validate/test tokenized article abstracts\n",
    "* Load the model\n",
    "* Use the model to assign topics probability to all articles\n",
    "* Save the topic assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf52110d-2f75-47e1-a130-d123c0fbb781",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d1b5cc8-7a69-465b-bd84-8da0aaca9e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data'\n",
    "MODELS_PATH = '../models'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0465b3-e910-497b-a418-45a000034f42",
   "metadata": {},
   "source": [
    "## Load the tokenized data\n",
    "Load the dictionary and the tokenized data for the train/validate/test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92e813d4-96aa-498d-a1ef-4d10ce60bcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_PATH, 'dictionary.pickle'), 'rb') as handle:\n",
    "    dictionary = tokenized_dataset = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2be99528-43b7-440c-bf25-9654e09ae689",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tokenized_dataset(file_name):\n",
    "    path = os.path.join(DATA_PATH, file_name)\n",
    "    with open(path, 'rb') as handle:\n",
    "        tokenized_dataset = pickle.load(handle)\n",
    "    return tokenized_dataset\n",
    "\n",
    "def load_tokenized_datasets():\n",
    "    corpus_train = load_tokenized_dataset(\"corpus_train.pickle\")\n",
    "    corpus_validate = load_tokenized_dataset(\"corpus_validate.pickle\")\n",
    "    corpus_test = load_tokenized_dataset(\"corpus_test.pickle\")\n",
    "    return corpus_train, corpus_validate, corpus_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc4ce984-a567-4d55-9ec1-4fc91e24f2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_train, corpus_validate, corpus_test = load_tokenized_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b533f4-8886-4fd4-b2ce-75ce9822c118",
   "metadata": {},
   "source": [
    "## Load the topic model\n",
    "The model is the topic model fitted in 02_fit_topic_model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7291bc5e-2f1b-40a8-98b0-1b793d676d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(MODELS_PATH, 'topic_model.pickle'), 'rb') as handle:\n",
    "    topic_model = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21760ac0-abbd-4c12-a83d-dce43f6d3ce5",
   "metadata": {},
   "source": [
    "## Assign topics\n",
    "Use the model to assign topics probabilities to all articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f36a0d0b-d74e-44e1-8c37-cfcc91634f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_details(topic_model, corpus):\n",
    "    \"\"\"\n",
    "    Returns a list of pandas Series object of tuples. \n",
    "    Each tuple is a topic number and the topic probability for this entry in the corpus.\n",
    "    Example: \n",
    "        [[(0, 0.22764261), (4, 0.14444388), (5, 0.62411755)],\n",
    "         [(1, 0.024827635), (2, 0.3290665), (3, 0.6061594), (5, 0.03431195)],\n",
    "         [(0, 0.06239689), (3, 0.03924617), (5, 0.8926314)],\n",
    "         [(3, 0.09784623), (5, 0.89414346)],...\n",
    "        ...]\n",
    "    If for a given entry, the topic's probability is 0, then the topic is not included in the Series for this entry.\n",
    "    \"\"\"\n",
    "    topic_details_list = []\n",
    "    for row in topic_model[corpus]:\n",
    "        topic_details_list.append(row)\n",
    "    return topic_details_list\n",
    "\n",
    "def get_topic_dataframe(topic_model, corpus):\n",
    "    \"\"\"\n",
    "    Returns a data frame with a column for each topic in the topic model.\n",
    "    Each row stands for an entry in the corpus, each value for the probability of thos topic for this entry.\n",
    "    If for a given entry, the topic's probability is 0, the the value in the entry's column corresponding to the topic is also 0.\n",
    "    Example:\n",
    "             \t0 \t1 \t2 \t3 \t4 \t5\n",
    "        0 \t0.227641 \t0.000000 \t0.000000 \t0.000000 \t0.144445 \t0.624118\n",
    "        1 \t0.000000 \t0.024817 \t0.329062 \t0.606161 \t0.000000 \t0.034325\n",
    "        2 \t0.062392 \t0.000000 \t0.000000 \t0.039281 \t0.000000 \t0.892601\n",
    "        3 \t0.000000 \t0.000000 \t0.000000 \t0.097728 \t0.000000 \t0.894262\n",
    "    \"\"\"\n",
    "    topic_details = get_topic_details(topic_model, corpus)\n",
    "    topics_entries = []  # topics for all entries\n",
    "    num_topics = len(topic_model.get_topics())  # number of topics in the model\n",
    "    for row in topic_details:\n",
    "        topics_entry = [0] * num_topics\n",
    "        for entry in row:  # all topic probabilities for this entry\n",
    "            topic_num = entry[0]  # the topic number\n",
    "            topic_prob = entry[1]  # the topic probability            \n",
    "            topics_entry[topic_num] = topic_prob\n",
    "        topics_entries.append(topics_entry)\n",
    "    return pd.DataFrame(topics_entries, columns=range(0, num_topics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff617bb7-e055-4015-adbf-f9cef146ab90",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_train_df = get_topic_dataframe(topic_model, corpus_train)\n",
    "topics_validate_df = get_topic_dataframe(topic_model, corpus_validate)\n",
    "topics_test_df = get_topic_dataframe(topic_model, corpus_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651f5910-9ad6-4cbf-b03e-173ccef946fa",
   "metadata": {},
   "source": [
    "### Save the topics\n",
    "For each train/validate/test dataset, save the assigned topics as separate csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "553b60ef-b999-4228-9ac7-29ef9aca237e",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_train_df.to_csv(os.path.join(DATA_PATH, 'topics_train.csv'))\n",
    "topics_validate_df.to_csv(os.path.join(DATA_PATH, 'topics_validate.csv'))\n",
    "topics_test_df.to_csv(os.path.join(DATA_PATH, 'topics_test.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
