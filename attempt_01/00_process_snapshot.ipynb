{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7854bfc-d370-4c0e-92d3-4e235dae1ca7",
   "metadata": {},
   "source": [
    "# Process snapshot\n",
    "\n",
    "* Download a snapshop of arXiv [arXiv.org submitters, 2024] manually, put it in folder data.\n",
    "* Load the snapshot into a dataframe\n",
    "* Add columns for date and general categories\n",
    "* Save it in CSV format\n",
    "\n",
    "## References\n",
    "arXiv.org submitters. (2024). arXiv Dataset [Data set]. Kaggle. https://doi.org/10.34740/KAGGLE/DSV/7548853"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f23424d-812b-4bb2-8e2c-75f8cd10e4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9197e1df-d639-45d9-bf74-c1f5517d84b2",
   "metadata": {},
   "source": [
    "## Load the snapshot into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f37ca4ea-9009-455f-acb0-108341a4b9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8914e9b2-b84b-42ca-b4d8-01e957515160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file\n",
      "Processed 100000 / 2412624 lines\n",
      "Processed 200000 / 2412624 lines\n",
      "Processed 300000 / 2412624 lines\n",
      "Processed 400000 / 2412624 lines\n",
      "Processed 500000 / 2412624 lines\n",
      "Processed 600000 / 2412624 lines\n",
      "Processed 700000 / 2412624 lines\n",
      "Processed 800000 / 2412624 lines\n",
      "Processed 900000 / 2412624 lines\n",
      "Processed 1000000 / 2412624 lines\n",
      "Processed 1100000 / 2412624 lines\n",
      "Processed 1200000 / 2412624 lines\n",
      "Processed 1300000 / 2412624 lines\n",
      "Processed 1400000 / 2412624 lines\n",
      "Processed 1500000 / 2412624 lines\n",
      "Processed 1600000 / 2412624 lines\n",
      "Processed 1700000 / 2412624 lines\n",
      "Processed 1800000 / 2412624 lines\n",
      "Processed 1900000 / 2412624 lines\n",
      "Processed 2000000 / 2412624 lines\n",
      "Processed 2100000 / 2412624 lines\n",
      "Processed 2200000 / 2412624 lines\n",
      "Processed 2300000 / 2412624 lines\n",
      "Processed 2400000 / 2412624 lines\n",
      "CPU times: user 7min 42s, sys: 6.82 s, total: 7min 49s\n",
      "Wall time: 7min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# path to snapshot of data\n",
    "snapshot_path = os.path.join(DATA_PATH, 'arxiv-metadata-oai-snapshot.json')\n",
    "\n",
    "frames = []\n",
    "max_bytes = -1  # 1024 * 1024 * 10  # max bytes to read from file at a time\n",
    "# one json per line\n",
    "with open(snapshot_path) as json_file:    \n",
    "    print(\"Reading file\")\n",
    "    lines = json_file.readlines(max_bytes)\n",
    "    line_count = len(lines)\n",
    "    counter = 0\n",
    "    for line in lines:\n",
    "        # load semi-structured JSON data into data frame (https://pandas.pydata.org/docs/reference/api/pandas.json_normalize.html)\n",
    "        data = json.loads(line)\n",
    "        normalized_data = pd.json_normalize(data)\n",
    "        frames.append(normalized_data)\n",
    "        # print progress info\n",
    "        counter += 1\n",
    "        if counter % 100000 == 0: print(f\"Processed {counter} / {line_count} lines\")\n",
    "# put result into data frame\n",
    "arxiv_df = pd.concat(frames, ignore_index=True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2281dd88-9b95-4537-9938-576fbfbfe929",
   "metadata": {},
   "source": [
    "## Add date columns\n",
    "\n",
    "Extract date of first version from the version column, add 'year' and 'month' columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbed5979-c556-468e-8764-752a3692c51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "created = [version[0]['created'] for version in arxiv_df['versions']]\n",
    "arxiv_df['created'] = pd.DatetimeIndex(created)\n",
    "arxiv_df['year'] = [datetime.year for datetime in arxiv_df['created']]\n",
    "arxiv_df['month'] = [datetime.month for datetime in arxiv_df['created']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab965fb-723f-48e7-9fcb-c2f5f6e26365",
   "metadata": {},
   "source": [
    "## Add general category columns\n",
    "\n",
    "Add a column with a less specific category, e.g. arXiv category \"physics.gen-ph\" -> general category \"physics\"\n",
    "\n",
    "See: https://arxiv.org/category_taxonomy\n",
    "\n",
    "Note that \"math.GM\" and \"physics.gen-ph\" are ragbag categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54389207-2c30-476e-a9b5-0bb1d4d46a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_categories = []  # the categories for all entries\n",
    "for categories in arxiv_df['categories']:\n",
    "    categories = categories.split()\n",
    "    entry_categories = []  # the categorie(s) for this publication\n",
    "    for category in categories:\n",
    "        entry_category = category\n",
    "        if (\"cs.\" in category) or (\"cmp-lg\" in category): entry_categories.append(\"Computer Science\")\n",
    "        elif \"econ.\" in category: entry_categories.append(\"Economics\")\n",
    "        elif \"eess.\" in category: entry_categories.append(\"Electrical Engineering and Systems Science\")\n",
    "        elif (\"math.\" in category) or (\"alg-geom\" in category) or (\"dg-ga\" in category) or (\"funct-an\" in category) or (\"dg-ga\" in category) or (\"q-alg\" in category): \n",
    "            if \"math.GM\" in category: entry_categories.append(\"General\")  # General Mathematics is a bin for papers that are obviously wrong\n",
    "            else: entry_categories.append(\"Mathematics\")\n",
    "        elif \"physics.gen-ph\" in category: entry_categories.append(\"General\")  # General Physics is a bin for papers that are obviously wrong\n",
    "        elif (\"astro-ph\" in category) or (\"cond-mat.\" in category) or (\"gr-qc\" in category) or \\\n",
    "             (\"hep-\" in category) or (\"math-ph\" in category) or (\"nlin.\" in category)  or (\"nucl-\" in category) or \\\n",
    "             (\"physics.\" in category) or (\"quant-ph\" in category) or (\"acc-phys\" in category) or (\"adap-org\" in category) or \\\n",
    "             (\"ao-sci\" in category) or (\"atom-ph\" in category) or (\"bayes-an\" in category) or \\\n",
    "             (\"chao-dyn\" in category) or (\"chem-ph\" in category) or (\"comp-gas\" in category) or \\\n",
    "             (\"cond-mat\" in category) or (\"mtrl-th\" in category) or (\"patt-sol\" in category) or \\\n",
    "             (\"plasm-ph\" in category) or (\"solv-int\" in category): entry_categories.append(\"Physics\")\n",
    "        elif (\"q-bio.\" in category) or (\"q-bio\" in category) or (\"supr-con\" in category): entry_categories.append(\"Quantitative Biology\")\n",
    "        elif \"q-fin\" in category: entry_categories.append(\"Quantitative Finance\")\n",
    "        elif \"stat.\" in category: entry_categories.append(\"Statistics\")\n",
    "        else: entry_categories.append(category)\n",
    "    entry_categories = list(set(entry_categories))\n",
    "    gen_categories.append(entry_categories)\n",
    "gen_categories = pd.Series(gen_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98830f66-d2dc-4aca-8748-f6fc2c12cd30",
   "metadata": {},
   "source": [
    "One-hot encode the new categories, add then to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62af5e89-b5d9-4c24-b52a-e61fc22d7392",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = gen_categories.str.join('|').str.get_dummies()\n",
    "arxiv_df = arxiv_df.join(one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c858dd-cbc7-438c-b7d3-2f0de8f314a3",
   "metadata": {},
   "source": [
    "## Save as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47f8abb8-e08f-4529-8a5b-f8d980f70a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = os.path.join(DATA_PATH, 'arxiv_metadata.csv')\n",
    "arxiv_df.to_csv(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ff4b22-89b5-430b-8034-33cfc8a3b77e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
