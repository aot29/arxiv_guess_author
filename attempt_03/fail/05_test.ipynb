{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97146dde-de0d-4fc3-8482-d195fd7a1c33",
   "metadata": {},
   "source": [
    "# Test\n",
    "* Find the authors closest to the articles in the topic space.\n",
    "* Compute the probability that the closest author is one of the authors of the article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f3ffccf1-c753-4e8a-81cc-547cd1087a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2081b5e4-a045-4cc7-a748-d51fd74bc90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data'\n",
    "MODELS_PATH = '../models'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2f8b14-3820-49fd-8a8b-d5b7fedcf278",
   "metadata": {},
   "source": [
    "## load the article metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "90157ff5-911f-4b55-8541-6bb5e4ca3a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df(name):\n",
    "    return pd.read_csv(\n",
    "        os.path.join(DATA_PATH, name), \n",
    "        index_col=0, \n",
    "        converters={\"authors_parsed\": lambda x:[entry.replace(\"'\", '').strip(\"[]\") for entry in x.split(\"', '\")]}\n",
    "    )\n",
    "\n",
    "validate_df = load_df('validate_topics9.csv')\n",
    "test_df = load_df('test_topics9.csv')\n",
    "train_df = load_df('train_topics9.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfafce6-f671-4bf6-aa41-5487004709b6",
   "metadata": {},
   "source": [
    "## Find the authors closest to the articles in the topic space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c5185a76-c04e-49f1-b38d-5629978dd84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the topics by author\n",
    "authors_validate_df = pd.read_csv(os.path.join(DATA_PATH, 'validate_topics9_authors.csv'), index_col=0)\n",
    "authors_test_df = pd.read_csv(os.path.join(DATA_PATH, 'test_topics9_authors.csv'), index_col=0)\n",
    "authors_train_df = pd.read_csv(os.path.join(DATA_PATH, 'train_topics9_authors.csv'), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d992bde4-f100-4027-9c72-50cb3f94edb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def topic_distance(topics1, topics2):\n",
    "    \"\"\"\n",
    "    topic1, topic2: numpy.ndarray, representing the probability that an article is about a topic. An article can have multiple topics.\n",
    "    Example:\n",
    "        0    0.000000\n",
    "        1    0.000000\n",
    "        2    0.000000\n",
    "        3    0.000000\n",
    "        4    0.000000\n",
    "        5    0.992668\n",
    "    topic1 and topic2 must be the same length.\n",
    "    Topics were assigned to articles in 03_assign_topics\n",
    "    \"\"\"\n",
    "    dist = np.linalg.norm(topics1 - topics2)  # euclidean distance, L2 norm is default\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca1a0c5-67bc-4e62-ac07-009081442ec3",
   "metadata": {},
   "source": [
    "Load the topic model\n",
    "Load the LDA topic model fitted in [03_fit_topic_model](./03_fit_topic_model.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fec671aa-dc51-4278-9817-d6f05d1459d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(MODELS_PATH, 'topic_model9.pickle'), 'rb') as handle:\n",
    "    topic_model = pickle.load(handle)\n",
    "\n",
    "num_topics = len(topic_model.get_topics())  # number of topics in the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4f9d00-469f-4d5b-96a1-24f0296925ac",
   "metadata": {},
   "source": [
    "### Example 1\n",
    "Pick a random article from the validate data set, find the nearest author in validate dataset.\n",
    "Expect to guess one of the authors in the majority of cases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "086bb61c-324e-44c5-988e-84b321c4e429",
   "metadata": {},
   "outputs": [],
   "source": [
    "def guess_author(article, authors_df, topics_authors_np):\n",
    "    \"\"\"\n",
    "    Guess the author of article within authors_df.\n",
    "    \n",
    "    article: pandas.DataFrame data for a single article\n",
    "    authors_df: pandas.DataFrame data for all authors\n",
    "    authors_np: numpy.array topics of all authors\n",
    "    \"\"\"\n",
    "    # numpy array with topics probabilities for the article\n",
    "    topics1 = np.array(article[[\"topic9_%d\"%n for n in range(num_topics)]])\n",
    "    # compute distances between article topics and topics of all authors\n",
    "    distances = [topic_distance(topics1, topics2) for topics2 in topics_authors_np]\n",
    "    # find the closest author\n",
    "    closest_author = authors_df.iloc[distances.index(min(distances))].author\n",
    "    return closest_author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4f74af2e-a74a-4347-898b-562746cc3f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original article \"Electrical Tuning of Neutral and Charged Excitons with 1-nm Gate\" authors are: ['Almutlaq, Jawaher, ', 'Wang, Jiangtao, ', 'Li, Linsen, ', 'Li, Chao, ', 'Dang, Tong, ', 'Bulović, Vladimir, ', 'Kong, Jing, ', 'Englund, Dirk, ']\n",
      "The closest author is: Bulović, Vladimir, \n"
     ]
    }
   ],
   "source": [
    "# pick a random paper\n",
    "rnd_article = validate_df.sample()\n",
    "topics_authors_validate_np = authors_validate_df[authors_validate_df.columns.drop('author')].to_numpy() \n",
    "closest_author = guess_author(rnd_article, authors_validate_df, topics_authors_validate_np)\n",
    "\n",
    "# check\n",
    "print(f\"The original article \\\"{rnd_article.title.iloc[0]}\\\" authors are: {rnd_article.authors_parsed.iloc[0]}\")\n",
    "print(f\"The closest author is: {closest_author}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c10c68b9-3a89-4016-967d-70f264a26640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "closest_author in rnd_article.authors_parsed.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9826ac39-a792-4881-8920-d41f7c55197c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guessed the authors of 85/100 articles correctly, i.e. 85.00 %\n",
      "CPU times: user 17.1 s, sys: 0 ns, total: 17.1 s\n",
      "Wall time: 17.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "MAX_SAMPLES = 100\n",
    "correct = 0\n",
    "topics_authors_validate_np = authors_validate_df[authors_validate_df.columns.drop('author')].to_numpy() \n",
    "for i in range(MAX_SAMPLES):\n",
    "    rnd_article = validate_df.sample()\n",
    "    closest_author = guess_author(rnd_article, authors_validate_df, topics_authors_validate_np)\n",
    "    if closest_author in rnd_article.authors_parsed.iloc[0]:\n",
    "        correct += 1\n",
    "print(f\"Guessed the authors of {correct}/{MAX_SAMPLES} articles correctly, i.e. {correct/MAX_SAMPLES*100:.2f} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0060938-137f-4ac9-8abf-0fa6b3e952ea",
   "metadata": {},
   "source": [
    "### Example 2\n",
    "Pick a random article from the validate data set, by an author who is also in the train dataset. Find the nearest author in train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8871659f-e6a0-485e-8177-af19f738da20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The validate dataset has 101576, the train dataset has 157213, and 50935 are in both datasets.\n"
     ]
    }
   ],
   "source": [
    "# Percentage of authors in validate dataset, that are also present in train dataset\n",
    "authors_validate_set = set(authors_validate_df.author)\n",
    "authors_train_set = set(authors_train_df.author)\n",
    "authors_intersection = authors_validate_set.intersection(authors_train_set)\n",
    "print(f\"The validate dataset has {len(authors_validate_set)}, the train dataset has {len(authors_train_set)}, and {len(authors_intersection)} are in both datasets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f66d0834-8c56-4910-8270-01443052ad25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19005 out of 22632 articles in the validate dataset were written by authors present in the validate and the train datasets\n",
      "i.e. 83.97 %\n"
     ]
    }
   ],
   "source": [
    "# get articles in validate dataset, written by authors who are in both datasets\n",
    "intersection_ids = []\n",
    "for i, row in validate_df.iterrows():\n",
    "    for author in row.authors_parsed:\n",
    "        # if at least one author is in both datasets, keep the article id\n",
    "        if author in authors_intersection:\n",
    "            intersection_ids.append(row.id)\n",
    "            break\n",
    "\n",
    "idx = [article_id in intersection_ids for article_id in validate_df.id]\n",
    "intersection_articles_df = validate_df[idx]\n",
    "\n",
    "print(f\"{intersection_articles_df.shape[0]} out of {validate_df.shape[0]} articles in the validate dataset were written by authors present in the validate and the train datasets\")\n",
    "print(f\"i.e. {intersection_articles_df.shape[0]/validate_df.shape[0]*100:.2f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "848a9683-bdd0-469f-91f8-de1172c4f823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original article \"Iterative Methods for an Inverse Eddy Current Problem with Total\n",
      "  Variation Regularization\" authors are: ['Chen, Junqing, ', 'Long, Zehao, ']\n",
      "The closest author is: Kobayashi, Miki, \n"
     ]
    }
   ],
   "source": [
    "# pick a random paper\n",
    "rnd_article = intersection_articles_df.sample()\n",
    "topics_authors_train_np = authors_train_df[authors_train_df.columns.drop('author')].to_numpy() \n",
    "closest_author = guess_author(rnd_article, authors_train_df, topics_authors_train_np)\n",
    "\n",
    "# check\n",
    "print(f\"The original article \\\"{rnd_article.title.iloc[0]}\\\" authors are: {rnd_article.authors_parsed.iloc[0]}\")\n",
    "print(f\"The closest author is: {closest_author}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "0c9aa92a-b688-430f-a3df-4504301b7e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing article 1 / 19018\n",
      "Processing article 1001 / 19018\n",
      "Processing article 2001 / 19018\n",
      "Processing article 3001 / 19018\n",
      "Processing article 4001 / 19018\n",
      "Processing article 5001 / 19018\n",
      "Processing article 6001 / 19018\n",
      "Processing article 7001 / 19018\n",
      "Processing article 8001 / 19018\n",
      "Processing article 9001 / 19018\n",
      "Processing article 10001 / 19018\n",
      "Processing article 11001 / 19018\n",
      "Processing article 12001 / 19018\n",
      "Processing article 13001 / 19018\n",
      "Processing article 14001 / 19018\n",
      "Processing article 15001 / 19018\n",
      "Processing article 16001 / 19018\n",
      "Processing article 17001 / 19018\n",
      "Processing article 18001 / 19018\n",
      "Processing article 19001 / 19018\n",
      "Guessed the authors of 10/22632 articles correctly, i.e. 0.04 %\n",
      "CPU times: user 1h 32min, sys: 16.3 s, total: 1h 32min 17s\n",
      "Wall time: 1h 32min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "MAX_SAMPLES = 100\n",
    "correct = 0\n",
    "for i in range(MAX_SAMPLES):\n",
    "    rnd_article = validate_df.sample()\n",
    "    topics_authors_validate_np = authors_validate_df[authors_validate_df.columns.drop('author')].to_numpy() \n",
    "    closest_author = guess_author(rnd_article, authors_validate_df, topics_authors_validate_np)\n",
    "    if closest_author in rnd_article.authors_parsed.iloc[0]:\n",
    "        correct += 1\n",
    "print(f\"Guessed the authors of {correct}/{MAX_SAMPLES} articles correctly, i.e. {correct/MAX_SAMPLES*100:.2f} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d06abf2-62ec-4388-8bfd-a09366e0b0be",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "a41eb7b1-ec1b-40e8-9f63-fea0fe7576e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topics for the authors in the train dataset\n",
    "# the topic_authors dataframes have an extra column for author names, so use the 5 first columns only\n",
    "topics_authors_np = train_topics_authors.iloc[:, 0:5].to_numpy()  \n",
    "\n",
    "def guess_author(article_topics):\n",
    "    # numpy array with topics probabilities for the article\n",
    "    topics1 = np.array(article)\n",
    "    # compute distance from article topics to all authors topics in the train dataset\n",
    "    distances = [topic_distance(topics1, topics2) for topics2 in topics_authors_np]\n",
    "    # find closest author\n",
    "    closest_author = train_topics_authors.iloc[distances.index(min(distances))]\n",
    "    return closest_author\n",
    "\n",
    "def guess_authors(article_topics_df, article_df):\n",
    "    closest_authors = []\n",
    "    for i, article in article_topics_df.iterrows():\n",
    "        if i % 1000 == 0:\n",
    "            print(f\"Processing article {i+1}/{article_topics_df.shape[0]}\")\n",
    "        closest_authors.append(guess_author(article))\n",
    "    return closest_authors\n",
    "\n",
    "def check_guess(article_df, closest_authors):\n",
    "    for i, article in article_df.iterrows():\n",
    "        # check if correct\n",
    "        check.append(closest_author[i].author in article.authors_parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "512998f9-d6a2-4d9b-a164-d2b98ba7217b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 236 ms, sys: 23.8 ms, total: 260 ms\n",
      "Wall time: 245 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                  0.119213\n",
       "1                       0.0\n",
       "2                       0.0\n",
       "3                       0.0\n",
       "4                  0.870843\n",
       "author    Snegirev, A. V., \n",
       "Name: 46206, dtype: object"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "guess_author(topics_train_df.iloc[0])\n",
    "\n",
    "#guesses = guess_authors(topics_train_df, train_df)\n",
    "#check = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f010137-49b4-48f3-a2f0-39d1c7cb039b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
